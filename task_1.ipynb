{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NERC task with CoNLL 2003\n",
    "\n",
    "This is the first part of the task dedicated to reserching *Named Entity Recognition and Classification (NERC)* task applying to the *CoNLL 2003 dataset*. In this step we need find the best way to generate markup for the dataset in the subsequent steps. Also, we will experiment with prompt engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "\n",
    "First of all, we need to import necessery libraries and download our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import multiprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://llm.ispras.ru/api/chat/completions\"\n",
    "API_MODEL_URL = \"https://llm.ispras.ru/api/models\"\n",
    "API_KEY = \"YOUR_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"eriktks/conll2003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the information about the dataset. We have three splits: 'train', 'validation', 'test'.\n",
    "\n",
    "`dataset.keys()` - to see what splits we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first example in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_tags': [11, 0, 11, 21, 11, 12, 0, 11, 13, 11, 12, 0],\n",
      " 'id': '0',\n",
      " 'ner_tags': [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      " 'pos_tags': [21, 8, 22, 37, 22, 22, 6, 22, 15, 12, 21, 7],\n",
      " 'tokens': ['SOCCER',\n",
      "            '-',\n",
      "            'JAPAN',\n",
      "            'GET',\n",
      "            'LUCKY',\n",
      "            'WIN',\n",
      "            ',',\n",
      "            'CHINA',\n",
      "            'IN',\n",
      "            'SURPRISE',\n",
      "            'DEFEAT',\n",
      "            '.']}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[\"test\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the number of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train':  14041 examples.\n",
      "Split 'validation':  3250 examples.\n",
      "Split 'test':  3453 examples.\n"
     ]
    }
   ],
   "source": [
    "for split in dataset.keys():\n",
    "    dataset_split = dataset[split]\n",
    "    split_len = len(dataset_split)\n",
    "    print(f\"Split '{split}':  {split_len} examples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Tags\n",
    "\n",
    "The original dataset uses named entity recognition (NER) tags in the IOB2 format.\n",
    "\n",
    "Each token is annotated with three types of tags:\n",
    "1. POS Tags: Indicate the token's grammatical role (e.g., 'NN', 'VB', etc.).\n",
    "2. Chunk Tags: Specify the syntactic chunk the token belongs to (e.g., 'B-NP', 'I-NP').\n",
    "3. NER Tags: Identify named entities using the IOB2 scheme:\n",
    "   - 'O'      : Token is not part of any entity.\n",
    "   - 'B-PER'  : Beginning of a person entity.\n",
    "   - 'I-PER'  : Inside a person entity.\n",
    "   - 'B-ORG'  : Beginning of an organization entity.\n",
    "   - 'I-ORG'  : Inside an organization entity.\n",
    "   - 'B-LOC'  : Beginning of a location entity.\n",
    "   - 'I-LOC'  : Inside a location entity.\n",
    "   - 'B-MISC' : Beginning of a miscellaneous entity.\n",
    "   - 'I-MISC' : Inside a miscellaneous entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = {'\"': 0, \"''\": 1, '#': 2, '$': 3, '(': 4, ')': 5, ',': 6, '.': 7, ':': 8, '``': 9, 'CC': 10, 'CD': 11, 'DT': 12,\n",
    " 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'LS': 19, 'MD': 20, 'NN': 21, 'NNP': 22, 'NNPS': 23,\n",
    " 'NNS': 24, 'NN|SYM': 25, 'PDT': 26, 'POS': 27, 'PRP': 28, 'PRP$': 29, 'RB': 30, 'RBR': 31, 'RBS': 32, 'RP': 33,\n",
    " 'SYM': 34, 'TO': 35, 'UH': 36, 'VB': 37, 'VBD': 38, 'VBG': 39, 'VBN': 40, 'VBP': 41, 'VBZ': 42, 'WDT': 43,\n",
    " 'WP': 44, 'WP$': 45, 'WRB': 46}\n",
    "\n",
    "chunk_tags = {'O': 0, 'B-ADJP': 1, 'I-ADJP': 2, 'B-ADVP': 3, 'I-ADVP': 4, 'B-CONJP': 5, 'I-CONJP': 6, 'B-INTJ': 7, 'I-INTJ': 8,\n",
    " 'B-LST': 9, 'I-LST': 10, 'B-NP': 11, 'I-NP': 12, 'B-PP': 13, 'I-PP': 14, 'B-PRT': 15, 'I-PRT': 16, 'B-SBAR': 17,\n",
    " 'I-SBAR': 18, 'B-UCP': 19, 'I-UCP': 20, 'B-VP': 21, 'I-VP': 22}\n",
    "\n",
    "ner_tags = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence is split into tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.ListScalar: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[\"train\"][\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use sentences in model we need to group tokens to lists for each sentences with function `get_sentence`.\n",
    "\n",
    "After generating we will have the batch with random sentences to send them to the model.\n",
    "\n",
    "The function `generate_corps` takes dataset_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(dataset_name: str, idx: int) -> str: \n",
    "    return ' '.join(dataset.data[dataset_name][\"tokens\"][idx].values.tolist())\n",
    "\n",
    "def generate_corps(size: int, dataset_name: str):\n",
    "    data = dataset[dataset_name]\n",
    "    data_size = data.shape[0]\n",
    "    return (get_sentence(dataset_name, idx) \n",
    "            for idx in random.choices(range(data_size), k=size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for batch of 10 random sentences:\n",
    "\n",
    "```python\n",
    "generate_corps(10, \"train\"), sep='\\n'\n",
    "```\n",
    "\n",
    "we will have the batch of unannotated sentances.\n",
    "\n",
    "```bash\n",
    "delivered to consumer\n",
    "shares outstanding\n",
    "3 - Wayne Ferreira ( South Africa ) beat Jiri Novak ( Czech\n",
    "LECIVA PRAHA 2470.00 2470.00 1360 3359.200\n",
    "BOSTON AT CALIFORNIA\n",
    "-- Helsinki Newsroom +358 - 0 - 680 50 245\n",
    "More than 1,000 people have been executed in drug-related cases since the law took effect in 1989 .\n",
    "In another scene , a young girl performed oral sex with an unidentified adult man .\n",
    "Essex 532-8\n",
    "ACC sold 9.4 million tonnes in 1995/96 , retaining its top position in the Indian cement industry , Palkhivala said .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was close to the market 's forecast of net profits of 61.94 billion .\n",
      "Dhar 5 Yellow 12,700-12,800 12,750-12,900\n"
     ]
    }
   ],
   "source": [
    "print(*generate_corps(2, \"train\"), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model requests\n",
    "\n",
    "To make the request to the models let's make the request's head and body. And see the available models list to use them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all models names:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_names():\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    response = requests.get(API_MODEL_URL, headers=headers)\n",
    "    if response.status_code // 100 == 2:\n",
    "        data = response.json()\n",
    "        models = data.get(\"data\", [])\n",
    "        model_names = [model[\"name\"] for model in models]\n",
    "        return model_names\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_names():\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    response = requests.get(API_MODEL_URL, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        models = data.get(\"data\", [])\n",
    "        model_names = [model[\"name\"] for model in models]\n",
    "        return model_names\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama3.3:latest',\n",
      " 'llama3.1:70b',\n",
      " 'llama3.1:405b',\n",
      " 'gemma2:27b',\n",
      " 'mistral-large:123b',\n",
      " 'command-r-plus:104b',\n",
      " 'llama3.1:8b',\n",
      " 'krith/qwen2.5-coder-32b-instruct:IQ3_M',\n",
      " 'deepseek-coder-v2:236b',\n",
      " 'llama3.2:latest',\n",
      " 'mistral:7b',\n",
      " 'RuadaptQwen2.5-32B-Pro-Beta:Q8',\n",
      " 'deepseek-r1:14b',\n",
      " 'deepseek-r1:70b',\n",
      " 'deepseek-r1:7b',\n",
      " 'deepseek-r1:8b',\n",
      " 'qwen2.5-coder:1.5b',\n",
      " 'qwen2.5-coder:32b-instruct-q8_0']\n"
     ]
    }
   ],
   "source": [
    "model_names = get_all_model_names()\n",
    "\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the body of request we construct several prompts with different description of the task to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = lambda sentence: f\"Classify all named entities in a sentence and categorize their semantic meaning: '{sentence}'\"\n",
    "\n",
    "prompt_2 = lambda sentence, tags: f\"Classify all named entities in a sentence: '{sentence}', based on following tags: {tags}\"\n",
    "\n",
    "prompt_3 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Classify all named entities in a sentence: '{sentence}', \\\n",
    "based on following parts of speech tags: {pos_tags}, \\\n",
    "based on following chunk tags: {chunk_tags}, \\\n",
    "based on following named entity recognition tags: {ner_tags}\"\n",
    "\n",
    "prompt_4 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Determine each entity that can be classified and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following: '{sentence}'.\" \n",
    "\n",
    "prompt_5 = lambda sentences, pos_tags, chunk_tags, ner_tags: f\"\"\"Determine each entity that can be classified and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following sentences: {', '.join(f\"'{sentence}'\" for sentence in sentences)}.\"\"\"\n",
    "\n",
    "prompt_4_1 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Determine each entity that can be classified, split it into tokens and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following: '{sentence}'.\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate the request's payload, accepting prompt as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_payload(prompt):\n",
    "    return {\n",
    "        \"model\": \"llama3.3:latest\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            } \n",
    "        ],\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "def perform_request(prompt: str):\n",
    "    return (\n",
    "        requests.post(API_URL, headers=headers, json=gen_payload(prompt))\n",
    "        .json()\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example response with prompt_4 we get using perform_request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sentence = tuple(generate_corps(1, \"train\"))\n",
    "single_prompt = prompt_4(single_sentence, pos_tags, chunk_tags, ner_tags)\n",
    "\n",
    "response = perform_request(single_prompt)\n",
    "# pprint(response)\n",
    "# pprint((json.loads(response[\"choices\"][0][\"message\"][\"content\"]), single_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make multiprocessing request to make the responces from model faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('MARKET TALK - USDA net change in weekly export commitments for the week ended August 22 , includes old crop and new crop , were : wheat up 595,400 tonnes old , nil new ; corn up 1,900 old , up 319,600 new ; soybeans down 12,300 old , up 300,800 new ; upland cotton up 50,400 bales new , nil old ; soymeal 54,800 old , up 100,600 new , soyoil nil old , up 75,000 new ; barley up 1,700 old , nil new ; sorghum 6,200 old , up 156,700 new ; pima cotton up 4,000 bales old , nil new ; rice up 49,900 old , nil new ...',\n",
       "  'On Monday , the company said it had agreed to be acquired by WorldCom Inc in a deal valued at $ 14 billion .',\n",
       "  'ATRIA SEES H2 RESULT UP ON H1 .',\n",
       "  'Burnley 2 Walsall 1',\n",
       "  'Lokomotiva Kosice 2 Kerametal Dubnica 0'),\n",
       " ('Grand Prix athletics meeting on Friday :',\n",
       "  'Goalkeepers - Oliver Kahn , Andreas Koepke , Oliver Reck',\n",
       "  'Because of speculation in the market we introduced certain measures , but they are not draconian measures , and we brought it down to earth . \"',\n",
       "  'LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours .',\n",
       "  'Hamilton 2 Clyde 0'),\n",
       " ('Masterkova dominated the middle-distance races at the recent Atlanta Games following her return to competition this season after a three-year maternity break .',\n",
       "  'division soccer match on Friday :',\n",
       "  'Dinamo Bucharest 4 3 0 1 6 2 9',\n",
       "  '\" Somebody threw a molotov cocktail over the fence and it went into the parking lot .',\n",
       "  'Manchester United v Blackburn'),\n",
       " ('18,000',\n",
       "  'Penrose had been working for the charity which provides food to civilians for only a few weeks before he was captured .',\n",
       "  'NEW YORK',\n",
       "  'At least 16 people were killed and several injured on Sunday when a bus fell from a mountain road into a ravine on a river bank in Pakistan-ruled Azad ( free ) Kashmir , police said .',\n",
       "  'Iran accuses Iraq of ceasefire violations .'),\n",
       " ('He was a politician , one of the first French romantic writers and ambassador to the British court .',\n",
       "  '1996-08-23',\n",
       "  '1.206 bln 9 days',\n",
       "  'The maul was there and I was going to go in but I thought I should hold off because we had the ball .',\n",
       "  'EASTERN DIVISION'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corps = tuple(tuple(generate_corps(5, \"train\")) for _ in range(5))\n",
    "corps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test prompt_5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = tuple(prompt_5(corp, pos_tags, chunk_tags, ner_tags) for corp in corps )\n",
    "with multiprocessing.Pool(10) as p: \n",
    "    responses = p.map(perform_request, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform into dictionary the results we got from the prompt_5:\n",
    "\n",
    "(In the prompt_5 we are trying to send to the model multiply sentences in a single request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'entity': 'MARKET',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'TALK',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'USDA',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'August',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'wheat',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'tonnes',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'corn',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soybeans',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'cotton',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'bales',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soymeal',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soyoil',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'barley',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'sorghum',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'pima cotton',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'rice',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Monday',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'WorldCom Inc',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'ATRIA',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'H2',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'H1',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Burnley',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Walsall',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Lokomotiva Kosice',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Kerametal Dubnica',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'}]},\n",
      "  ('MARKET TALK - USDA net change in weekly export commitments for the week '\n",
      "   'ended August 22 , includes old crop and new crop , were : wheat up 595,400 '\n",
      "   'tonnes old , nil new ; corn up 1,900 old , up 319,600 new ; soybeans down '\n",
      "   '12,300 old , up 300,800 new ; upland cotton up 50,400 bales new , nil old '\n",
      "   '; soymeal 54,800 old , up 100,600 new , soyoil nil old , up 75,000 new ; '\n",
      "   'barley up 1,700 old , nil new ; sorghum 6,200 old , up 156,700 new ; pima '\n",
      "   'cotton up 4,000 bales old , nil new ; rice up 49,900 old , nil new ...',\n",
      "   'On Monday , the company said it had agreed to be acquired by WorldCom Inc '\n",
      "   'in a deal valued at $ 14 billion .',\n",
      "   'ATRIA SEES H2 RESULT UP ON H1 .',\n",
      "   'Burnley 2 Walsall 1',\n",
      "   'Lokomotiva Kosice 2 Kerametal Dubnica 0')),\n",
      " ({'entities': [{'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Grand Prix',\n",
      "                 'ner_tag': ['B-MISC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Friday',\n",
      "                 'ner_tag': ['B-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Oliver Kahn',\n",
      "                 'ner_tag': ['B-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Andreas Koepke',\n",
      "                 'ner_tag': ['I-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Oliver Reck',\n",
      "                 'ner_tag': ['I-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'the market',\n",
      "                 'ner_tag': ['O'],\n",
      "                 'pos_tag': ['DT', 'NN']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Lattakia',\n",
      "                 'ner_tag': ['B-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Tartous',\n",
      "                 'ner_tag': ['I-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Aug 10',\n",
      "                 'ner_tag': ['O'],\n",
      "                 'pos_tag': ['NNP', 'CD']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Hamilton',\n",
      "                 'ner_tag': ['B-ORG'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Clyde',\n",
      "                 'ner_tag': ['I-ORG'],\n",
      "                 'pos_tag': ['NNP']}]},\n",
      "  ('Grand Prix athletics meeting on Friday :',\n",
      "   'Goalkeepers - Oliver Kahn , Andreas Koepke , Oliver Reck',\n",
      "   'Because of speculation in the market we introduced certain measures , but '\n",
      "   'they are not draconian measures , and we brought it down to earth . \"',\n",
      "   'LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 '\n",
      "   'hours .',\n",
      "   'Hamilton 2 Clyde 0')),\n",
      " ({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Masterkova',\n",
      "                 'ner_tag': 'B-PER',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Atlanta Games',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Friday',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Dinamo Bucharest',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Manchester United',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Blackburn',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'}]},\n",
      "  ('Masterkova dominated the middle-distance races at the recent Atlanta Games '\n",
      "   'following her return to competition this season after a three-year '\n",
      "   'maternity break .',\n",
      "   'division soccer match on Friday :',\n",
      "   'Dinamo Bucharest 4 3 0 1 6 2 9',\n",
      "   '\" Somebody threw a molotov cocktail over the fence and it went into the '\n",
      "   'parking lot .',\n",
      "   'Manchester United v Blackburn')),\n",
      " ({'entities': [{'chunk_tag': ['O', 0],\n",
      "                 'ner_tag': ['O', 0],\n",
      "                 'pos_tag': ['CD', 11],\n",
      "                 'text': '18,000'},\n",
      "                {'chunk_tags': [['B-NP', 11],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-VP', 21],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-ADVP', 3],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0]],\n",
      "                 'ner_tags': [['B-PER', 1],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0]],\n",
      "                 'pos_tags': [['NNP', 22],\n",
      "                              ['VBD', 38],\n",
      "                              ['VBN', 40],\n",
      "                              ['VBG', 39],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['WDT', 43],\n",
      "                              ['VBZ', 42],\n",
      "                              ['TO', 35],\n",
      "                              ['PRP', 28],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['TO', 35],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['RB', 30],\n",
      "                              ['DT', 12],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['PRP', 28],\n",
      "                              ['VBD', 38],\n",
      "                              ['VBG', 39]],\n",
      "                 'text': 'Penrose had been working for the charity which '\n",
      "                         'provides food to civilians for only a few weeks '\n",
      "                         'before he was captured .'},\n",
      "                {'chunk_tag': ['B-NP', 11],\n",
      "                 'ner_tag': ['B-LOC', 5],\n",
      "                 'pos_tag': ['NNP', 22],\n",
      "                 'text': 'NEW YORK'},\n",
      "                {'chunk_tags': [['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['B-ADJP', 1],\n",
      "                                ['I-ADJP', 2],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['O', 0]],\n",
      "                 'ner_tags': [['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['I-MISC', -1],\n",
      "                              ['I-MISC', -1],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['I-LOC', 6]],\n",
      "                 'pos_tags': [['TO', 35],\n",
      "                              ['CD', 11],\n",
      "                              ['NNS', 24],\n",
      "                              ['VBD', 38],\n",
      "                              ['CC', 10],\n",
      "                              ['JJ', 16],\n",
      "                              ['VBN', 40],\n",
      "                              ['IN', 15],\n",
      "                              ['NNP', 22],\n",
      "                              ['NN', 21],\n",
      "                              ['TO', 35],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['NN', 21],\n",
      "                              ['CC', 10],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['NNP', 22],\n",
      "                              ['HYPH', -1],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNP', 22],\n",
      "                              [')', 5],\n",
      "                              ['VBZ', 42]],\n",
      "                 'text': 'At least 16 people were killed and several injured '\n",
      "                         'on Sunday when a bus fell from a mountain road into '\n",
      "                         'a ravine on a river bank in Pakistan-ruled Azad ( '\n",
      "                         'free ) Kashmir , police said .'},\n",
      "                {'chunk_tag': ['B-NP', 11],\n",
      "                 'ner_tag': ['B-LOC', 5],\n",
      "                 'pos_tag': ['NNP', 22],\n",
      "                 'text': 'Iran'}]},\n",
      "  ('18,000',\n",
      "   'Penrose had been working for the charity which provides food to civilians '\n",
      "   'for only a few weeks before he was captured .',\n",
      "   'NEW YORK',\n",
      "   'At least 16 people were killed and several injured on Sunday when a bus '\n",
      "   'fell from a mountain road into a ravine on a river bank in Pakistan-ruled '\n",
      "   'Azad ( free ) Kashmir , police said .',\n",
      "   'Iran accuses Iraq of ceasefire violations .')),\n",
      " ({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'PRP',\n",
      "                 'text': 'He'},\n",
      "                {'chunk_tag': 'B-VP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'VBD',\n",
      "                 'text': 'was'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'DT',\n",
      "                 'text': 'a politician'},\n",
      "                {'chunk_tag': 'O', 'ner_tag': 'O', 'pos_tag': ',', 'text': ','},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': 'one of the first French romantic writers and '\n",
      "                         'ambassador to the British court .'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': '1996-08-23'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': '1.206 bln 9 days'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'DT',\n",
      "                 'text': 'The maul was there and I was going to go in but I '\n",
      "                         'thought I should hold off because we had the ball .'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'I-MISC',\n",
      "                 'pos_tag': 'NNP',\n",
      "                 'text': 'EASTERN DIVISION'}]},\n",
      "  ('He was a politician , one of the first French romantic writers and '\n",
      "   'ambassador to the British court .',\n",
      "   '1996-08-23',\n",
      "   '1.206 bln 9 days',\n",
      "   'The maul was there and I was going to go in but I thought I should hold '\n",
      "   'off because we had the ball .',\n",
      "   'EASTERN DIVISION'))]\n"
     ]
    }
   ],
   "source": [
    "pprint([(json.loads(response[\"choices\"][0][\"message\"][\"content\"] ), corp) for response, corp in zip(responses, corps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senting model too much sentences to execute maybe too long, so the version to make it faster by sending one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = tuple(prompt_4_1(sentence, pos_tags, chunk_tags, ner_tags) for sentence in corps)\n",
    "with multiprocessing.Pool(10) as p: \n",
    "    responses = p.map(perform_request, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(predicted_markup, expected_markup):\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
