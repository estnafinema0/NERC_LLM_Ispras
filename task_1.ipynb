{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NERC task with CoNLL 2003\n",
    "\n",
    "This is the first part of the task dedicated to reserching *Named Entity Recognition and Classification (NERC)* task applying to the *CoNLL 2003 dataset*. In this step we need find the best way to generate markup for the dataset in the subsequent steps. Also, we will experiment with prompt engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "\n",
    "First of all, we need to import necessery libraries and download our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import multiprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://llm.ispras.ru/api/chat/completions\"\n",
    "API_MODEL_URL = \"https://llm.ispras.ru/api/models\"\n",
    "API_KEY = \"YOUR_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"eriktks/conll2003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the information about the dataset. We have three splits: 'train', 'validation', 'test'.\n",
    "\n",
    "`dataset.keys()` - to see what splits we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first example in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_tags': [11, 0, 11, 21, 11, 12, 0, 11, 13, 11, 12, 0],\n",
      " 'id': '0',\n",
      " 'ner_tags': [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      " 'pos_tags': [21, 8, 22, 37, 22, 22, 6, 22, 15, 12, 21, 7],\n",
      " 'tokens': ['SOCCER',\n",
      "            '-',\n",
      "            'JAPAN',\n",
      "            'GET',\n",
      "            'LUCKY',\n",
      "            'WIN',\n",
      "            ',',\n",
      "            'CHINA',\n",
      "            'IN',\n",
      "            'SURPRISE',\n",
      "            'DEFEAT',\n",
      "            '.']}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[\"test\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the number of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train':  14041 examples.\n",
      "Split 'validation':  3250 examples.\n",
      "Split 'test':  3453 examples.\n"
     ]
    }
   ],
   "source": [
    "for split in dataset.keys():\n",
    "    dataset_split = dataset[split]\n",
    "    split_len = len(dataset_split)\n",
    "    print(f\"Split '{split}':  {split_len} examples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of tags in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution NER tags: Counter({0: 250660, 5: 10645, 1: 10059, 3: 9323, 2: 6991, 4: 5290, 7: 5062, 8: 1717, 6: 1671})\n"
     ]
    }
   ],
   "source": [
    "def analyze_tags(dataset):\n",
    "    ner_tags_counter = Counter()\n",
    "    for split in dataset.keys():\n",
    "        for example in dataset[split]:\n",
    "            ner_tags_counter.update(example[\"ner_tags\"])\n",
    "    print(\"Distribution NER tags:\", ner_tags_counter)\n",
    "\n",
    "analyze_tags(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Tags\n",
    "\n",
    "The original dataset uses named entity recognition (NER) tags in the IOB2 format.\n",
    "\n",
    "Each token is annotated with three types of tags:\n",
    "1. POS Tags: Indicate the token's grammatical role (e.g., 'NN', 'VB', etc.).\n",
    "2. Chunk Tags: Specify the syntactic chunk the token belongs to (e.g., 'B-NP', 'I-NP').\n",
    "3. NER Tags: Identify named entities using the IOB2 scheme:\n",
    "   - 'O'      : Token is not part of any entity.\n",
    "   - 'B-PER'  : Beginning of a person entity.\n",
    "   - 'I-PER'  : Inside a person entity.\n",
    "   - 'B-ORG'  : Beginning of an organization entity.\n",
    "   - 'I-ORG'  : Inside an organization entity.\n",
    "   - 'B-LOC'  : Beginning of a location entity.\n",
    "   - 'I-LOC'  : Inside a location entity.\n",
    "   - 'B-MISC' : Beginning of a miscellaneous entity.\n",
    "   - 'I-MISC' : Inside a miscellaneous entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = {'\"': 0, \"''\": 1, '#': 2, '$': 3, '(': 4, ')': 5, ',': 6, '.': 7, ':': 8, '``': 9, 'CC': 10, 'CD': 11, 'DT': 12,\n",
    " 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'LS': 19, 'MD': 20, 'NN': 21, 'NNP': 22, 'NNPS': 23,\n",
    " 'NNS': 24, 'NN|SYM': 25, 'PDT': 26, 'POS': 27, 'PRP': 28, 'PRP$': 29, 'RB': 30, 'RBR': 31, 'RBS': 32, 'RP': 33,\n",
    " 'SYM': 34, 'TO': 35, 'UH': 36, 'VB': 37, 'VBD': 38, 'VBG': 39, 'VBN': 40, 'VBP': 41, 'VBZ': 42, 'WDT': 43,\n",
    " 'WP': 44, 'WP$': 45, 'WRB': 46}\n",
    "\n",
    "chunk_tags = {'O': 0, 'B-ADJP': 1, 'I-ADJP': 2, 'B-ADVP': 3, 'I-ADVP': 4, 'B-CONJP': 5, 'I-CONJP': 6, 'B-INTJ': 7, 'I-INTJ': 8,\n",
    " 'B-LST': 9, 'I-LST': 10, 'B-NP': 11, 'I-NP': 12, 'B-PP': 13, 'I-PP': 14, 'B-PRT': 15, 'I-PRT': 16, 'B-SBAR': 17,\n",
    " 'I-SBAR': 18, 'B-UCP': 19, 'I-UCP': 20, 'B-VP': 21, 'I-VP': 22}\n",
    "\n",
    "ner_tags = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence is split into tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.ListScalar: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[\"train\"][\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use sentences in model we need to group tokens to lists for each sentences with function `get_sentence`.\n",
    "\n",
    "After generating we will have the batch with random sentences to send them to the model.\n",
    "\n",
    "The function `generate_corps` takes dataset_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(dataset_name: str, idx: int) -> str: \n",
    "    return ' '.join(dataset.data[dataset_name][\"tokens\"][idx].values.tolist())\n",
    "\n",
    "def generate_corps(size: int, dataset_name: str):\n",
    "    data = dataset[dataset_name]\n",
    "    data_size = data.shape[0]\n",
    "    return (get_sentence(dataset_name, idx) \n",
    "            for idx in random.choices(range(data_size), k=size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for batch of 10 random sentences:\n",
    "\n",
    "```python\n",
    "generate_corps(10, \"train\"), sep='\\n'\n",
    "```\n",
    "\n",
    "we will have the batch of unannotated sentances.\n",
    "\n",
    "```bash\n",
    "delivered to consumer\n",
    "shares outstanding\n",
    "3 - Wayne Ferreira ( South Africa ) beat Jiri Novak ( Czech\n",
    "LECIVA PRAHA 2470.00 2470.00 1360 3359.200\n",
    "BOSTON AT CALIFORNIA\n",
    "-- Helsinki Newsroom +358 - 0 - 680 50 245\n",
    "More than 1,000 people have been executed in drug-related cases since the law took effect in 1989 .\n",
    "In another scene , a young girl performed oral sex with an unidentified adult man .\n",
    "Essex 532-8\n",
    "ACC sold 9.4 million tonnes in 1995/96 , retaining its top position in the Indian cement industry , Palkhivala said .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was close to the market 's forecast of net profits of 61.94 billion .\n",
      "Dhar 5 Yellow 12,700-12,800 12,750-12,900\n"
     ]
    }
   ],
   "source": [
    "print(*generate_corps(2, \"train\"), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model requests\n",
    "\n",
    "To make the request to the models let's make the request's head and body. And see the available models list to use them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all models names:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_names():\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    response = requests.get(API_MODEL_URL, headers=headers)\n",
    "    if response.status_code // 100 == 2:\n",
    "        data = response.json()\n",
    "        models = data.get(\"data\", [])\n",
    "        model_names = [model[\"name\"] for model in models]\n",
    "        return model_names\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_names():\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    response = requests.get(API_MODEL_URL, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        models = data.get(\"data\", [])\n",
    "        model_names = [model[\"name\"] for model in models]\n",
    "        return model_names\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama3.3:latest',\n",
      " 'llama3.1:70b',\n",
      " 'llama3.1:405b',\n",
      " 'gemma2:27b',\n",
      " 'mistral-large:123b',\n",
      " 'command-r-plus:104b',\n",
      " 'llama3.1:8b',\n",
      " 'krith/qwen2.5-coder-32b-instruct:IQ3_M',\n",
      " 'deepseek-coder-v2:236b',\n",
      " 'llama3.2:latest',\n",
      " 'mistral:7b',\n",
      " 'RuadaptQwen2.5-32B-Pro-Beta:Q8',\n",
      " 'deepseek-r1:14b',\n",
      " 'deepseek-r1:70b',\n",
      " 'deepseek-r1:7b',\n",
      " 'deepseek-r1:8b',\n",
      " 'qwen2.5-coder:1.5b',\n",
      " 'qwen2.5-coder:32b-instruct-q8_0']\n"
     ]
    }
   ],
   "source": [
    "model_names = get_all_model_names()\n",
    "\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the body of request we construct several prompts with different description of the task to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = lambda sentence: f\"Classify all named entities in a sentence and categorize their semantic meaning: '{sentence}'\"\n",
    "\n",
    "prompt_2 = lambda sentence, tags: f\"Classify all named entities in a sentence: '{sentence}', based on following tags: {tags}\"\n",
    "\n",
    "prompt_3 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Classify all named entities in a sentence: '{sentence}', \\\n",
    "based on following parts of speech tags: {pos_tags}, \\\n",
    "based on following chunk tags: {chunk_tags}, \\\n",
    "based on following named entity recognition tags: {ner_tags}\"\n",
    "\n",
    "prompt_4 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Determine each entity that can be classified and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following: '{sentence}'.\" \n",
    "\n",
    "prompt_4_1 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"Determine each entity that can be classified, split it into tokens and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following: '{sentence}'.\" \n",
    "\n",
    "prompt_5 = lambda sentences, pos_tags, chunk_tags, ner_tags: f\"\"\"Determine each entity that can be classified and assign them a pos_tag, a chunk_tag and a ner_tag, using following lists: \\\n",
    "parts of speech tags: [{pos_tags}], \\\n",
    "chunk tags: [{chunk_tags}], \\\n",
    "named entity recognition tags: [{ner_tags}] from the following sentences: {', '.join(f\"'{sentence}'\" for sentence in sentences)}.\"\"\"\n",
    "\n",
    "prompt_6 = lambda sentence, pos_tags, chunk_tags, ner_tags: f\"\"\"Identify each named entity in the sentence and classify it by the following tags:\n",
    "    - POS tags: {pos_tags}\n",
    "    - Chunk tags: {chunk_tags}\n",
    "    - NER tags: {ner_tags}\n",
    "    Sentence: '{sentence}'\n",
    "    Return the response in JSON format with the fields: text, pos_tag, chunk_tag, der_tag.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate the request's payload, accepting prompt as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_payload(prompt):\n",
    "    return {\n",
    "        \"model\": \"llama3.3:latest\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            } \n",
    "        ],\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "def perform_request(prompt: str):\n",
    "    return (\n",
    "        requests.post(API_URL, headers=headers, json=gen_payload(prompt))\n",
    "        .json()\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example response with prompt_4 we get using perform_request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sentence = tuple(generate_corps(1, \"train\"))\n",
    "single_prompt = prompt_4(single_sentence, pos_tags, chunk_tags, ner_tags)\n",
    "\n",
    "response = perform_request(single_prompt)\n",
    "# pprint(response)\n",
    "# pprint((json.loads(response[\"choices\"][0][\"message\"][\"content\"]), single_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make multiprocessing request to make the responces from model faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('MARKET TALK - USDA net change in weekly export commitments for the week ended August 22 , includes old crop and new crop , were : wheat up 595,400 tonnes old , nil new ; corn up 1,900 old , up 319,600 new ; soybeans down 12,300 old , up 300,800 new ; upland cotton up 50,400 bales new , nil old ; soymeal 54,800 old , up 100,600 new , soyoil nil old , up 75,000 new ; barley up 1,700 old , nil new ; sorghum 6,200 old , up 156,700 new ; pima cotton up 4,000 bales old , nil new ; rice up 49,900 old , nil new ...',\n",
       "  'On Monday , the company said it had agreed to be acquired by WorldCom Inc in a deal valued at $ 14 billion .',\n",
       "  'ATRIA SEES H2 RESULT UP ON H1 .',\n",
       "  'Burnley 2 Walsall 1',\n",
       "  'Lokomotiva Kosice 2 Kerametal Dubnica 0'),\n",
       " ('Grand Prix athletics meeting on Friday :',\n",
       "  'Goalkeepers - Oliver Kahn , Andreas Koepke , Oliver Reck',\n",
       "  'Because of speculation in the market we introduced certain measures , but they are not draconian measures , and we brought it down to earth . \"',\n",
       "  'LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours .',\n",
       "  'Hamilton 2 Clyde 0'),\n",
       " ('Masterkova dominated the middle-distance races at the recent Atlanta Games following her return to competition this season after a three-year maternity break .',\n",
       "  'division soccer match on Friday :',\n",
       "  'Dinamo Bucharest 4 3 0 1 6 2 9',\n",
       "  '\" Somebody threw a molotov cocktail over the fence and it went into the parking lot .',\n",
       "  'Manchester United v Blackburn'),\n",
       " ('18,000',\n",
       "  'Penrose had been working for the charity which provides food to civilians for only a few weeks before he was captured .',\n",
       "  'NEW YORK',\n",
       "  'At least 16 people were killed and several injured on Sunday when a bus fell from a mountain road into a ravine on a river bank in Pakistan-ruled Azad ( free ) Kashmir , police said .',\n",
       "  'Iran accuses Iraq of ceasefire violations .'),\n",
       " ('He was a politician , one of the first French romantic writers and ambassador to the British court .',\n",
       "  '1996-08-23',\n",
       "  '1.206 bln 9 days',\n",
       "  'The maul was there and I was going to go in but I thought I should hold off because we had the ball .',\n",
       "  'EASTERN DIVISION'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corps = tuple(tuple(generate_corps(5, \"train\")) for _ in range(5))\n",
    "corps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test prompt_5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = tuple(prompt_5(corp, pos_tags, chunk_tags, ner_tags) for corp in corps )\n",
    "with multiprocessing.Pool(10) as p: \n",
    "    responses = p.map(perform_request, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform into dictionary the results we got from the prompt_5:\n",
    "\n",
    "(In the prompt_5 we are trying to send to the model multiply sentences in a single request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'entity': 'MARKET',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'TALK',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'USDA',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'August',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'wheat',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'tonnes',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'corn',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soybeans',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'cotton',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'bales',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soymeal',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'soyoil',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'barley',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'sorghum',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'pima cotton',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'rice',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Monday',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'WorldCom Inc',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'ATRIA',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'H2',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'H1',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'NN'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Burnley',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Walsall',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Lokomotiva Kosice',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Kerametal Dubnica',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'}]},\n",
      "  ('MARKET TALK - USDA net change in weekly export commitments for the week '\n",
      "   'ended August 22 , includes old crop and new crop , were : wheat up 595,400 '\n",
      "   'tonnes old , nil new ; corn up 1,900 old , up 319,600 new ; soybeans down '\n",
      "   '12,300 old , up 300,800 new ; upland cotton up 50,400 bales new , nil old '\n",
      "   '; soymeal 54,800 old , up 100,600 new , soyoil nil old , up 75,000 new ; '\n",
      "   'barley up 1,700 old , nil new ; sorghum 6,200 old , up 156,700 new ; pima '\n",
      "   'cotton up 4,000 bales old , nil new ; rice up 49,900 old , nil new ...',\n",
      "   'On Monday , the company said it had agreed to be acquired by WorldCom Inc '\n",
      "   'in a deal valued at $ 14 billion .',\n",
      "   'ATRIA SEES H2 RESULT UP ON H1 .',\n",
      "   'Burnley 2 Walsall 1',\n",
      "   'Lokomotiva Kosice 2 Kerametal Dubnica 0')),\n",
      " ({'entities': [{'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Grand Prix',\n",
      "                 'ner_tag': ['B-MISC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Friday',\n",
      "                 'ner_tag': ['B-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Oliver Kahn',\n",
      "                 'ner_tag': ['B-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Andreas Koepke',\n",
      "                 'ner_tag': ['I-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Oliver Reck',\n",
      "                 'ner_tag': ['I-PER'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'the market',\n",
      "                 'ner_tag': ['O'],\n",
      "                 'pos_tag': ['DT', 'NN']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Lattakia',\n",
      "                 'ner_tag': ['B-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Tartous',\n",
      "                 'ner_tag': ['I-LOC'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Aug 10',\n",
      "                 'ner_tag': ['O'],\n",
      "                 'pos_tag': ['NNP', 'CD']},\n",
      "                {'chunk_tag': ['B-NP'],\n",
      "                 'entity': 'Hamilton',\n",
      "                 'ner_tag': ['B-ORG'],\n",
      "                 'pos_tag': ['NNP']},\n",
      "                {'chunk_tag': ['I-NP'],\n",
      "                 'entity': 'Clyde',\n",
      "                 'ner_tag': ['I-ORG'],\n",
      "                 'pos_tag': ['NNP']}]},\n",
      "  ('Grand Prix athletics meeting on Friday :',\n",
      "   'Goalkeepers - Oliver Kahn , Andreas Koepke , Oliver Reck',\n",
      "   'Because of speculation in the market we introduced certain measures , but '\n",
      "   'they are not draconian measures , and we brought it down to earth . \"',\n",
      "   'LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 '\n",
      "   'hours .',\n",
      "   'Hamilton 2 Clyde 0')),\n",
      " ({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Masterkova',\n",
      "                 'ner_tag': 'B-PER',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Atlanta Games',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Friday',\n",
      "                 'ner_tag': 'B-MISC',\n",
      "                 'pos_tag': 'NNP'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Dinamo Bucharest',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'entity': 'Manchester United',\n",
      "                 'ner_tag': 'B-ORG',\n",
      "                 'pos_tag': 'NNPS'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'entity': 'Blackburn',\n",
      "                 'ner_tag': 'I-ORG',\n",
      "                 'pos_tag': 'NNP'}]},\n",
      "  ('Masterkova dominated the middle-distance races at the recent Atlanta Games '\n",
      "   'following her return to competition this season after a three-year '\n",
      "   'maternity break .',\n",
      "   'division soccer match on Friday :',\n",
      "   'Dinamo Bucharest 4 3 0 1 6 2 9',\n",
      "   '\" Somebody threw a molotov cocktail over the fence and it went into the '\n",
      "   'parking lot .',\n",
      "   'Manchester United v Blackburn')),\n",
      " ({'entities': [{'chunk_tag': ['O', 0],\n",
      "                 'ner_tag': ['O', 0],\n",
      "                 'pos_tag': ['CD', 11],\n",
      "                 'text': '18,000'},\n",
      "                {'chunk_tags': [['B-NP', 11],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-VP', 21],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-ADVP', 3],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['O', 0],\n",
      "                                ['O', 0]],\n",
      "                 'ner_tags': [['B-PER', 1],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0]],\n",
      "                 'pos_tags': [['NNP', 22],\n",
      "                              ['VBD', 38],\n",
      "                              ['VBN', 40],\n",
      "                              ['VBG', 39],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['WDT', 43],\n",
      "                              ['VBZ', 42],\n",
      "                              ['TO', 35],\n",
      "                              ['PRP', 28],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['TO', 35],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['RB', 30],\n",
      "                              ['DT', 12],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNS', 24],\n",
      "                              ['IN', 15],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['PRP', 28],\n",
      "                              ['VBD', 38],\n",
      "                              ['VBG', 39]],\n",
      "                 'text': 'Penrose had been working for the charity which '\n",
      "                         'provides food to civilians for only a few weeks '\n",
      "                         'before he was captured .'},\n",
      "                {'chunk_tag': ['B-NP', 11],\n",
      "                 'ner_tag': ['B-LOC', 5],\n",
      "                 'pos_tag': ['NNP', 22],\n",
      "                 'text': 'NEW YORK'},\n",
      "                {'chunk_tags': [['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-VP', 22],\n",
      "                                ['I-VP', 22],\n",
      "                                ['B-ADJP', 1],\n",
      "                                ['I-ADJP', 2],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-NP', 11],\n",
      "                                ['I-NP', 12],\n",
      "                                ['I-NP', 12],\n",
      "                                ['O', 0],\n",
      "                                ['B-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['I-LOC', -1],\n",
      "                                ['O', 0]],\n",
      "                 'ner_tags': [['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['O', 0],\n",
      "                              ['B-MISC', 7],\n",
      "                              ['I-MISC', -1],\n",
      "                              ['I-MISC', -1],\n",
      "                              ['O', 0],\n",
      "                              ['O', 0],\n",
      "                              ['B-LOC', 5],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['I-LOC', 6],\n",
      "                              ['I-LOC', 6]],\n",
      "                 'pos_tags': [['TO', 35],\n",
      "                              ['CD', 11],\n",
      "                              ['NNS', 24],\n",
      "                              ['VBD', 38],\n",
      "                              ['CC', 10],\n",
      "                              ['JJ', 16],\n",
      "                              ['VBN', 40],\n",
      "                              ['IN', 15],\n",
      "                              ['NNP', 22],\n",
      "                              ['NN', 21],\n",
      "                              ['TO', 35],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['NN', 21],\n",
      "                              ['CC', 10],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['DT', 12],\n",
      "                              ['NN', 21],\n",
      "                              ['NN', 21],\n",
      "                              ['IN', 15],\n",
      "                              ['NNP', 22],\n",
      "                              ['HYPH', -1],\n",
      "                              ['JJ', 16],\n",
      "                              ['NNP', 22],\n",
      "                              [')', 5],\n",
      "                              ['VBZ', 42]],\n",
      "                 'text': 'At least 16 people were killed and several injured '\n",
      "                         'on Sunday when a bus fell from a mountain road into '\n",
      "                         'a ravine on a river bank in Pakistan-ruled Azad ( '\n",
      "                         'free ) Kashmir , police said .'},\n",
      "                {'chunk_tag': ['B-NP', 11],\n",
      "                 'ner_tag': ['B-LOC', 5],\n",
      "                 'pos_tag': ['NNP', 22],\n",
      "                 'text': 'Iran'}]},\n",
      "  ('18,000',\n",
      "   'Penrose had been working for the charity which provides food to civilians '\n",
      "   'for only a few weeks before he was captured .',\n",
      "   'NEW YORK',\n",
      "   'At least 16 people were killed and several injured on Sunday when a bus '\n",
      "   'fell from a mountain road into a ravine on a river bank in Pakistan-ruled '\n",
      "   'Azad ( free ) Kashmir , police said .',\n",
      "   'Iran accuses Iraq of ceasefire violations .')),\n",
      " ({'entities': [{'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'PRP',\n",
      "                 'text': 'He'},\n",
      "                {'chunk_tag': 'B-VP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'VBD',\n",
      "                 'text': 'was'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'DT',\n",
      "                 'text': 'a politician'},\n",
      "                {'chunk_tag': 'O', 'ner_tag': 'O', 'pos_tag': ',', 'text': ','},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': 'one of the first French romantic writers and '\n",
      "                         'ambassador to the British court .'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': '1996-08-23'},\n",
      "                {'chunk_tag': 'I-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'CD',\n",
      "                 'text': '1.206 bln 9 days'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'O',\n",
      "                 'pos_tag': 'DT',\n",
      "                 'text': 'The maul was there and I was going to go in but I '\n",
      "                         'thought I should hold off because we had the ball .'},\n",
      "                {'chunk_tag': 'B-NP',\n",
      "                 'ner_tag': 'I-MISC',\n",
      "                 'pos_tag': 'NNP',\n",
      "                 'text': 'EASTERN DIVISION'}]},\n",
      "  ('He was a politician , one of the first French romantic writers and '\n",
      "   'ambassador to the British court .',\n",
      "   '1996-08-23',\n",
      "   '1.206 bln 9 days',\n",
      "   'The maul was there and I was going to go in but I thought I should hold '\n",
      "   'off because we had the ball .',\n",
      "   'EASTERN DIVISION'))]\n"
     ]
    }
   ],
   "source": [
    "pprint([(json.loads(response[\"choices\"][0][\"message\"][\"content\"] ), corp) for response, corp in zip(responses, corps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senting model too much sentences to execute maybe too long, this prompt example was working more than 5 minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_49629/4197901741.py\", line 15, in perform_request\n",
      "    requests.post(API_URL, headers=headers, json=gen_payload(prompt))\n",
      "Process ForkPoolWorker-16:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-17:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ekaterina/.local/lib/python3.10/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/ekaterina/.local/lib/python3.10/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ekaterina/.local/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ekaterina/.local/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ekaterina/.local/lib/python3.10/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 700, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 446, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 441, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p: \n\u001b[0;32m----> 3\u001b[0m     responses \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mApply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03min a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(prompt_4_1(sentence, pos_tags, chunk_tags, ner_tags) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m corps)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p: \n\u001b[1;32m      3\u001b[0m     responses \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(perform_request, prompts)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:739\u001b[0m, in \u001b[0;36mPool.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:657\u001b[0m, in \u001b[0;36mPool.terminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterminating pool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m TERMINATE\n\u001b[0;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_terminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/util.py:224\u001b[0m, in \u001b[0;36mFinalize.__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     sub_debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalizer calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and kwargs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    223\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m--> 224\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weakref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    226\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:695\u001b[0m, in \u001b[0;36mPool._terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, change_notifier, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    692\u001b[0m task_handler\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m TERMINATE\n\u001b[1;32m    694\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelping task handler/workers to finish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_help_stuff_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43minqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m result_handler\u001b[38;5;241m.\u001b[39mis_alive()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(cache) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have cache with result_hander not alive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:675\u001b[0m, in \u001b[0;36mPool._help_stuff_finish\u001b[0;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_help_stuff_finish\u001b[39m(inqueue, task_handler, size):\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;66;03m# task_handler may be blocked trying to put items on inqueue\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremoving tasks from inqueue until task handler finished\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 675\u001b[0m     \u001b[43minqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m task_handler\u001b[38;5;241m.\u001b[39mis_alive() \u001b[38;5;129;01mand\u001b[39;00m inqueue\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mpoll():\n\u001b[1;32m    677\u001b[0m         inqueue\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mrecv()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompts = tuple(prompt_4_1(sentence, pos_tags, chunk_tags, ner_tags) for sentence in corps)\n",
    "with multiprocessing.Pool(10) as p: \n",
    "    responses = p.map(perform_request, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model with prompt_6:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = tuple(prompt_6(corp, pos_tags, chunk_tags, ner_tags) for corp in corps )\n",
    "with multiprocessing.Pool(10) as p: \n",
    "    responses = p.map(perform_request, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(predicted_markup, expected_markup):\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
